{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 1: What to do at the airport?\n",
        "\n",
        "You are travelling and have some time to kill at the aiport. There are three things you could spend your time doing:\n",
        "  \n",
        "1) You could have a coffee.\n",
        "\n",
        "This has a probability of $0.8$ of giving you time to relax with a tasty beverage, and a utility of $10$. \n",
        "It also has a probability of $0.2$ of providing you with a nasty cup from over-roasted beans that annoys you,\n",
        "and outcome with a utility of $-5$.\n",
        "\n",
        "2) You could shop for clothes.\n",
        "\n",
        "This has a probability of $0.1$ that you will find a great outfit at a good price, utility $20$. However, it \n",
        "has a probability of $0.9$ that you end up wasting money on over-priced junk, utility $-10$.\n",
        "\n",
        "3) You could have a bite to eat.\n",
        "\n",
        "This has a probability of $0.8$ that you find something rather mediocre that prevents you from being too hungry \n",
        "during your flight, utility $2$, and a probability of $0.2$ that you find something filling and tasty, utility $5$.\n",
        "\n",
        "> __QUESTION 1(a):__ What should you do if you take the principle of maximum expected utility to be your decision criterion?\n",
        "\n",
        "> __QUESTION 1(b):__ What should you do if you take the principle of maximax decision criterion to be your decision criterion?\n",
        "\n",
        "> __QUESTION 1(c):__ What should you do if you take the principle of maximin decision criterion to be your decision criterion?\n",
        "    "
      ],
      "metadata": {
        "id": "twbLWgpO7YQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 2: Solving a MDP with MDP toolbox\n",
        "\n",
        "We have four states and four actions.\n",
        "\n",
        "The actions are: 0 is Right, 1 is Left, 2 is Up and 3 is Down.\n",
        "\n",
        "The states are 0, 1, 2, 3, and they are arranged like this:\n",
        "    \n",
        "$$\n",
        "\\begin{array}{cc}\n",
        "2 & 3\\\\\n",
        "0 & 1\\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "The motion model provides:\n",
        "*   0.8 probability of moving in the direction of the action,\n",
        "*   0.1 probability of moving in each of the directions perpendicular to that of the action.\n",
        "\n",
        "So that 2 is Up from 0 and 1 is Right of 0, and so on. The cost of any action (in any state) is -0.04.\n",
        "\n",
        "In case of \"infeasible\" movements, the agent remains in the current state.\n",
        "\n",
        "The reward for state 3 is 1, and the reward for state 1 is -1, and the agent does not leave those states.\n",
        "\n",
        "Set discount factor equal to 0.99.\n",
        "\n",
        "> __QUESTION 2(a):__ What is the policy based on the Value iteration algorithm?\n",
        "\n",
        "> __QUESTION 2(b):__ What is the policy based on the Policy iteration algorithm?\n",
        "\n",
        "> __QUESTION 2(c):__ What is the policy based on the Q-Learning algorithm?\n",
        "\n",
        "> __QUESTION 2(d):__ Look at the **setVerbose**() function and the time attribute of the MDP objects in MDPToolbox and use them to compare the number of iterations (hint: see the iter attribute) and the CPU time used to come up with a solution (hint: see the time attribute) in the Value iteration algorithm and Policy iteration algorithm resolutions.\n"
      ],
      "metadata": {
        "id": "wRLlnsWJ90DZ"
      }
    }
  ]
}